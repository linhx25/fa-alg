{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class offline_eval_metric_cb:\n",
    "    def __init__(self, group, context, action, loss, prob = None):\n",
    "        \"\"\"\n",
    "        each parameter above is a T-dimension vector, collected from the online algorithm\n",
    "        (currently in the static version...)\n",
    "        group: the t-th incoming individual group, each in [m];\n",
    "        context: the t-th incoming individual feature (excluding group info), each is R_{dx} vector;\n",
    "        action: the t-th individual's action chosen by the agent, each in [K];\n",
    "        loss: the t-th loss (one step, not cummulative up to now) obtained from that individual, each in R;\n",
    "        prob: the chosen action prob (propensity score), each in Delta_{K};\n",
    "        \"\"\"\n",
    "        self.group = np.array(group)\n",
    "        self.individual_num = len(group)\n",
    "        self.group_num = len(set(group))\n",
    "        self.context = np.array(context)\n",
    "        self.action = np.array(action)\n",
    "        self.action_num = len(set(action))\n",
    "        self.loss = np.array(loss)\n",
    "        self.prob = np.array(prob)\n",
    "        #create a dataframe including {g_t, a_t, r_t} t = 1^T\n",
    "        self.offline_data = pd.DataFrame({\"group\": group, \"action\": action, \"step_loss\": loss})\n",
    "        self.summary_loss = {}\n",
    "        self.expected_action_parity_disable = True\n",
    "    def group_loss_parity(self):\n",
    "        cumu_group_loss = 0.001 * np.ones((self.individual_num, self.group_num))\n",
    "        cumu_group_num = 0.001 * np.ones((self.individual_num, self.group_num))\n",
    "        #parity between avg loss\n",
    "        loss_parity = np.zeros(self.individual_num)\n",
    "\n",
    "        #initialization\n",
    "        cumu_group_loss[0][self.group[0]] = self.loss[0]\n",
    "        cumu_group_num[0][self.group[0]] = 1\n",
    "        loss_parity[0] = self.loss[0]\n",
    "        for i in range(1, self.individual_num):\n",
    "            for k in range(self.group_num):\n",
    "                cumu_group_loss[i][k] = cumu_group_loss[i - 1][k]\n",
    "                cumu_group_num[i][k] = cumu_group_num[i - 1][k]\n",
    "\n",
    "            cumu_group_loss[i][self.group[i]] += self.loss[i]\n",
    "            cumu_group_num[i][self.group[i]] += 1\n",
    "            #compute the loss parity at each time t\n",
    "            avg_loss = [cumu_group_loss[i][k] / cumu_group_num[i][k] for k in range(self.group_num)]\n",
    "            avg_loss.sort()\n",
    "            loss_parity[i] = avg_loss[-1] - avg_loss[0]\n",
    "        cumu_group_loss = cumu_group_loss.T\n",
    "        cumu_group_num = cumu_group_num.T\n",
    "        cumu_loss = np.sum(cumu_group_loss, axis = 0)\n",
    "        \n",
    "        self.offline_data['cumu_loss'] = cumu_loss\n",
    "        self.summary_loss = {'cumu_loss': cumu_loss[-1]}\n",
    "        for k in range(self.group_num):\n",
    "            self.offline_data['cumu_loss_' + str(k)] = list(cumu_group_loss[k])\n",
    "            self.summary_loss['cumu_loss_' + str(k)] = cumu_group_loss[k][-1]\n",
    "            self.offline_data['cumu_num_' + str(k)] = list(cumu_group_num[k])\n",
    "        self.offline_data['loss_parity'] = list(loss_parity)\n",
    "        self.summary_loss['loss_parity'] = loss_parity[-1]\n",
    "        return self.summary_loss\n",
    "\n",
    "    \n",
    "    def group_action_parity_computation(self, prefix = 'realized'):\n",
    "        \"\"\"\n",
    "        realized action parity: from the realized action; \n",
    "        expected action parity: from the expected action simplex.\n",
    "        \"\"\"\n",
    "        ## 0.001 prevents the case where 0 is the denominator\n",
    "        avg_action_num = [0.001] * self.action_num\n",
    "        group_action_num = 0.001 * np.ones((self.group_num, self.action_num))\n",
    "        ## initialization\n",
    "        avg_action_num[self.action[0]] += 1\n",
    "        group_action_num[self.group[0]][self.action[0]] += 1\n",
    "        max_group_action_parity = np.zeros(self.individual_num)\n",
    "        for i in range(1, self.individual_num):\n",
    "            ## update num\n",
    "            if prefix == 'realized':\n",
    "                avg_action_num[self.action[i]] += 1\n",
    "                group_action_num[self.group[i]][self.action[i]] += 1\n",
    "            elif prefix == 'expected':\n",
    "                #see from the prob table\n",
    "                for j in range(self.action_num):\n",
    "                    avg_action_num[j] += self.prob[i][j]\n",
    "                    group_action_num[self.group[i]][j] += self.prob[i][j]\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "            ## update parity directly\n",
    "            group_action_parity = np.zeros(self.group_num)\n",
    "            for k in range(self.group_num):\n",
    "                group_action_parity[k] = np.sum([abs(avg_action_num[j]/(i + 1) - group_action_num[k][j]/sum(group_action_num[k])) \n",
    "                                                for j in range(self.action_num)])\n",
    "            print(group_action_parity)\n",
    "            max_group_action_parity[i] = max(group_action_parity)\n",
    "        #print(avg_action_num, group_action_num)\n",
    "        self.offline_data['group_action_parity_' + prefix] = list(max_group_action_parity)\n",
    "        self.summary_loss['group_action_parity_' + prefix] = max_group_action_parity[-1]\n",
    "        return self.summary_loss\n",
    "\n",
    "    def group_action_parity(self):\n",
    "        self.group_action_parity_computation('realized')\n",
    "        if self.expected_action_parity_disable == False:\n",
    "            self.group_action_parity_computation('expected')\n",
    "        \n",
    "    def individual_loss_parity_computation(self, prefix = 'realized', time_window = None, order = None):\n",
    "        \"\"\"\n",
    "        order: one-side or two-side (i.e. full time or hindsight), default None means two-side, i.e. the action for one individual is fair to both former and latter.\n",
    "        time_window: default None mean compute the unfairness from the start time until now, otherwise only compute K-step unfairness (moving window)\n",
    "        action_distance encoding (realized): if action are different, label action_distance to be 1 otherwise 0.\n",
    "        =sum indicate function {d(a_1, a_2) >= c1 * d(x1, x_2) + c2}\n",
    "        \"\"\"\n",
    "        loss_parity = np.zeros(self.individual_num) \n",
    "        c1 = 0.1\n",
    "        c2 = 0.5\n",
    "        if time_window == None:\n",
    "            if order == None:\n",
    "                for t1 in range(1, self.individual_num):\n",
    "                    loss_parity[t1] = loss_parity[t1 - 1]\n",
    "                    for t2 in range(t1):\n",
    "                        if self.action[t1] != self.action[t2]:\n",
    "                            #compute the feature distance to see if there is some unfairness\n",
    "                            if c1 * np.linalg.norm(self.context[t1] - self.context[t2]) + c2 >= 1:\n",
    "                                loss_parity[t1] += 1\n",
    "                self.offline_data['individual_loss_parity_' + prefix] = list(loss_parity)\n",
    "                self.summary_loss['individual_loss_parity_' + prefix] = loss_parity[-1]\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "\n",
    "       \n",
    "        else:\n",
    "            #(TODO): add other versions\n",
    "            raise NotImplementedError    \n",
    "\n",
    "    def individual_loss_parity(self):\n",
    "        #involve the interaction with the context...\n",
    "        self.individual_loss_parity_computation('realized')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99800399 0.99800399]\n",
      "[0.66566767 1.33133733]\n",
      "[0.33311126 0.99800399]\n",
      "[0.13311126 0.2       ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>action</th>\n",
       "      <th>step_loss</th>\n",
       "      <th>cumu_loss</th>\n",
       "      <th>cumu_loss_0</th>\n",
       "      <th>cumu_num_0</th>\n",
       "      <th>cumu_loss_1</th>\n",
       "      <th>cumu_num_1</th>\n",
       "      <th>loss_parity</th>\n",
       "      <th>group_action_parity_realized</th>\n",
       "      <th>individual_loss_parity_realized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.201</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.199201</td>\n",
       "      <td>0.998004</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.201</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.201</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.299201</td>\n",
       "      <td>1.331337</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.301</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.201</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.165867</td>\n",
       "      <td>0.998004</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.801</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.701</td>\n",
       "      <td>2.001</td>\n",
       "      <td>0.016342</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group  action  step_loss  cumu_loss  cumu_loss_0  cumu_num_0  cumu_loss_1  \\\n",
       "0      0       1        0.4      0.401          0.4         1.0        0.001   \n",
       "1      1       0        0.2      0.601          0.4         1.0        0.201   \n",
       "2      0       1        0.6      1.201          1.0         2.0        0.201   \n",
       "3      0       0        0.1      1.301          1.1         3.0        0.201   \n",
       "4      1       1        0.5      1.801          1.1         3.0        0.701   \n",
       "\n",
       "   cumu_num_1  loss_parity  group_action_parity_realized  \\\n",
       "0       0.001     0.400000                      0.000000   \n",
       "1       1.001     0.199201                      0.998004   \n",
       "2       1.001     0.299201                      1.331337   \n",
       "3       1.001     0.165867                      0.998004   \n",
       "4       2.001     0.016342                      0.200000   \n",
       "\n",
       "   individual_loss_parity_realized  \n",
       "0                              0.0  \n",
       "1                              0.0  \n",
       "2                              0.0  \n",
       "3                              0.0  \n",
       "4                              1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "group = [0, 1, 0, 0, 1]\n",
    "context = [3, 4, 2, 6, 1]\n",
    "action = [1, 0, 1, 0, 1]\n",
    "loss = [0.4, 0.2, 0.6, 0.1, 0.5]\n",
    "prob = [[0.2, 0.8], [0.6, 0.4], [0.1, 0.9], [0.7, 0.3], [0.2, 0.8]]\n",
    "metrics = offline_eval_metric_cb(group, context, action, loss, prob)\n",
    "metrics.group_loss_parity()\n",
    "metrics.group_action_parity()\n",
    "metrics.individual_loss_parity()\n",
    "metrics.offline_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cumu_loss': 1.8,\n",
       " 'cumu_loss_0': 1.1,\n",
       " 'cumu_loss_1': 0.7,\n",
       " 'loss_parity': 0.01666666666666672,\n",
       " 'group_action_parity_realized': 0.19999999999999996,\n",
       " 'group_action_parity_expected': 0.15999999999999992}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.summary_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## the falcon procedure, for the paper\n",
    "## https://arxiv.org/pdf/2003.12699.pdf\n",
    "from src.models.cb.FALCON import FALCON, FALCON_ldf, FALCON_price\n",
    "#from split_gz_csv import ds_files_csv, ds_files\n",
    "#from split import sample_custom_pmf\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#from glob_param import *\n",
    "from src.run_vw_job import process\n",
    "#from split import *\n",
    "import re\n",
    "rgx = re.compile('^average loss = (.*)$', flags=re.M)\n",
    "#show the regret performance in each algorithm\n",
    "\n",
    "csv_path = 'src/datasets/adult/adult_2.csv'\n",
    "# def alg_performance_regret(DS_DIR, did, alg_param, did_type):\n",
    "loss_param = []\n",
    "    # if did_type == 'openml':\n",
    "    #     sample_falcon = FALCON(csv_path, 95, 1)\n",
    "    # elif did_type == 'ms':\n",
    "    #     sample_falcon = FALCON_ldf(csv_path, 105, 1, 10)\n",
    "    # elif did_type == 'yahoo':\n",
    "    #     sample_falcon = FALCON_ldf(csv_path, 105, 1, 6, 'ridge')\n",
    "    # elif did_type == 'loan':\n",
    "    #     if did == 0:\n",
    "    #         sample_falcon = FALCON_price(csv_path, 10, 1, 15)\n",
    "    #     elif did == 1:\n",
    "    #         sample_falcon = FALCON_price(csv_path, 10, 1, 10)\n",
    "#gamma_param is a hyperparam in FALCON alg.\n",
    "sample_falcon = FALCON(csvpath = csv_path, gamma_param = 95, feed_choice = 1,\n",
    "                        group = ['sex', 'race'])\n",
    "    \n",
    "sample_falcon.learn_schedule()\n",
    "\n",
    "#cummulative loss for FALCON alg.\n",
    "sample_falcon.loss_all\n",
    "        \n",
    "    # gz_path = ds_files(DS_DIR)[did]\n",
    "    # for index in range(len(alg_param)):\n",
    "    #     pv_loss, output = process(gz_path, alg_param[index], None, True, did_type)\n",
    "    #     loss_param.append(list(output_extraction(output)))\n",
    "    # return loss_param"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
