{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src/datasets\n",
      "7841 32561\n"
     ]
    }
   ],
   "source": [
    "import src.datasets.tabular\n",
    "import src.datasets.utils\n",
    "from src.datasets.tabular import get_dataset_config\n",
    "\n",
    "## preprocessing for different datasets to vw format\n",
    "dataset = 'adult'\n",
    "dataset_kwargs = {'root_dir': 'src/datasets'}\n",
    "dataset_config = get_dataset_config(dataset, **dataset_kwargs)\n",
    "dset = src.datasets.utils.get_dataset(dataset_config)\n",
    "X_tr, y_tr, __, __, __, __ =  dset.get_data()\n",
    "\n",
    "print(sum(y_tr), len(y_tr))\n",
    "\n",
    "src.datasets.utils.save_vw_dataset(X_tr, y_tr, dataset, 'src/datasets/adult')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 1.00000000e+00, 2.00000100e+00, ...,\n",
       "       7.03300447e+03, 7.03299256e+03, 7.03399003e+03])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess, sys, os\n",
    "VW = 'vw'\n",
    "ds = 'src/datasets/adult/adult_2.vw.gz'\n",
    "cmd = [VW, ds, '-b', '24']\n",
    "# supervised\n",
    "# cmd += ['--oaa', '2']\n",
    "# contextual bandit\n",
    "## --progress 1 means we output all the time loss, otherwise it will only show the time point pow(2,k) \n",
    "## param details of different kinds of cb algs are in run_vw_job.py, i.e. the process function.\n",
    "cmd += ['--cbify', '2', '--bag', '4', '--progress', '1']\n",
    "output = subprocess.check_output(cmd, stderr=subprocess.STDOUT)\n",
    "#output = os.system('vw ' + ds + ' -b 24 --oaa 2') \n",
    "output = str(output, encoding = 'utf-8')\n",
    "from src.utils.joint_regret import output_extraction\n",
    "#the return of output_extraction function is the cummlative loss in terms of the time\n",
    "cum_loss = output_extraction(output)\n",
    "cum_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m[warning]\u001b[m Multiple data files passed as positional parameters, only the first one will be read and the rest will be ignored.\n",
      "using no cache\n",
      "Reading datafile = src/datasets/adult/adult_2.vw.gz\n",
      "num sources = 1\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "Enabled reductions: gd, scorer-identity, oaa\n",
      "Input label = MULTICLASS\n",
      "Output pred = MULTICLASS\n",
      "average  since         example        example        current        current  current\n",
      "loss     last          counter         weight          label        predict features\n",
      "0.000000 0.000000            1            1.0              1              1       11\n",
      "0.000000 0.000000            2            2.0              1              1       11\n",
      "0.000000 0.000000            4            4.0              1              1       12\n",
      "\u001b[32m[info]\u001b[m label 2 found -- labels are now considered 1-indexed.\n",
      "0.000000 0.000000            8            8.0              2              2       11\n",
      "0.437500 0.875000           16           16.0              1              2       12\n",
      "0.343750 0.250000           32           32.0              1              1       13\n",
      "0.265625 0.187500           64           64.0              2              1       11\n",
      "0.250000 0.234375          128          128.0              2              1       10\n",
      "0.218750 0.187500          256          256.0              2              1       11\n",
      "0.191406 0.164062          512          512.0              1              1       14\n",
      "0.183594 0.175781         1024         1024.0              1              1       11\n",
      "0.180176 0.176758         2048         2048.0              1              1       12\n",
      "0.173340 0.166504         4096         4096.0              1              2       11\n",
      "0.162354 0.151367         8192         8192.0              1              1       12\n",
      "0.159180 0.156006        16384        16384.0              1              1       11\n",
      "\n",
      "finished run\n",
      "number of examples = 32561\n",
      "weighted example sum = 32561.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.152974\n",
      "total feature number = 383812\n"
     ]
    }
   ],
   "source": [
    "!vw src/datasets/adult/adult_2.vw.gz 24 --oaa 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!vw src/datasets/german/german_2.vw.gz -b 24 --cbify 2 --regcbopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([   0.,    0.,    0., ..., 6008., 6008., 6008.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## the falcon procedure, for the paper\n",
    "## https://arxiv.org/pdf/2003.12699.pdf\n",
    "from src.models.cb.FALCON import FALCON, FALCON_ldf, FALCON_price\n",
    "#from split_gz_csv import ds_files_csv, ds_files\n",
    "#from split import sample_custom_pmf\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#from glob_param import *\n",
    "from src.run_vw_job import process\n",
    "#from split import *\n",
    "import re\n",
    "rgx = re.compile('^average loss = (.*)$', flags=re.M)\n",
    "#show the regret performance in each algorithm\n",
    "\n",
    "csv_path = 'src/datasets/adult/adult_2.csv'\n",
    "# def alg_performance_regret(DS_DIR, did, alg_param, did_type):\n",
    "loss_param = []\n",
    "    # if did_type == 'openml':\n",
    "    #     sample_falcon = FALCON(csv_path, 95, 1)\n",
    "    # elif did_type == 'ms':\n",
    "    #     sample_falcon = FALCON_ldf(csv_path, 105, 1, 10)\n",
    "    # elif did_type == 'yahoo':\n",
    "    #     sample_falcon = FALCON_ldf(csv_path, 105, 1, 6, 'ridge')\n",
    "    # elif did_type == 'loan':\n",
    "    #     if did == 0:\n",
    "    #         sample_falcon = FALCON_price(csv_path, 10, 1, 15)\n",
    "    #     elif did == 1:\n",
    "    #         sample_falcon = FALCON_price(csv_path, 10, 1, 10)\n",
    "#gamma_param is a hyperparam in FALCON alg.\n",
    "sample_falcon = FALCON(csv_path, 95, 1)\n",
    "    \n",
    "sample_falcon.learn_schedule()\n",
    "\n",
    "#cummulative loss for FALCON alg.\n",
    "sample_falcon.loss_all\n",
    "        \n",
    "    # gz_path = ds_files(DS_DIR)[did]\n",
    "    # for index in range(len(alg_param)):\n",
    "    #     pv_loss, output = process(gz_path, alg_param[index], None, True, did_type)\n",
    "    #     loss_param.append(list(output_extraction(output)))\n",
    "    # return loss_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([   0.,    0.,    0., ..., 5990., 5990., 5990.])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32561"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_all = output.split('\\n')\n",
    "res = []\n",
    "for i in range(len(output_all)):\n",
    "    if len(output_all[i].split(' ')) >= 50:\n",
    "        res.append(float(output_all[i].split(' ')[0]))\n",
    "        #print(len(output_all[i].split(' ')))\n",
    "    #print(len(output_all[i].split(' ')))\n",
    "len(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
